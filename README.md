# Seq2Seq Transliteration

Overview
This project implements **character-level Sequence-to-Sequence (Seq2Seq) models** for the task of transliterating Indian names between **English (Roman script)** and **Hindi (Devanagari script)**.  

The assignment is part of the *Introduction to NLP* course and focuses on building conditional language models that learn how to map sequences from one script to another.

Goal
The main objective was to design models that can:
- Capture the character-level patterns in Indian names.  
- Generate accurate Hindi transliterations given English input.  
- Compare different Seq2Seq architectures and decoding strategies.  

What We Explored
- **Baseline Seq2Seq with RNNs** – to understand core sequence modeling.  
- **Seq2Seq with Attention** – for better alignment between input and output.  
- **Decoding Strategies** – Greedy decoding vs. Beam Search for evaluation.  

Learning
This project helped me connect theory with practice by:
- Implementing Seq2Seq models from scratch.  
- Understanding why attention improves transliteration accuracy.  
- Experimenting with decoding strategies to see their impact.  

In short, this assignment was about **teaching machines to "translate sounds across scripts"**, and seeing how different model designs affect performance.
